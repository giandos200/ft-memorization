Namespace(adapter_reduction=None, add_adapter=False, add_canary=True, block_size=1024, canary_len=6, canary_rep=25, config_name=None, dataset_config_name=None, dataset_name='ptb_text_only', do_ref_model=False, eval_steps=100, gradient_accumulation_steps=8, hub_model_id=None, hub_token=None, learning_rate=2e-05, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, max_train_steps=None, model_name_or_path='gpt2', model_type=None, no_keep_linebreaks=False, num_train_epochs=3, num_warmup_steps=0, output_dir='./logs/', overwrite_cache=False, per_device_eval_batch_size=1, per_device_train_batch_size=1, preprocessing_num_workers=None, push_to_hub=False, seed=1234, tokenizer_name=None, train_file=None, train_head_only=True, train_layer_n_only=None, use_slow_tokenizer=False, validation_file=None, validation_split_percentage=5, weight_decay=0.0)
before canary len  42068
after canary len  42093
5000
model_params (million) 38.597376
model_params (million) 38.597376
training epoch 0
*************end of epoch 0 eval 
running canary eval
0.2815241338453503
threshold is:  3.645129919052124
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 0: perplexity: 51.16564797674889 perplexity_train: 81.61898867421712
____
0.0
51.16564797674889
81.61898867421712
_____
training epoch 1
*************end of epoch 1 eval 
running canary eval
0.5890265011627682
threshold is:  3.6049084663391113
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 1: perplexity: 48.699650526675164 perplexity_train: 76.58814697872296
____
0.0
48.699650526675164
76.58814697872296
_____
training epoch 2
*************end of epoch 2 eval 
running canary eval
0.7437620334707771
threshold is:  3.594428539276123
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 2: perplexity: 48.095677602178796 perplexity_train: 75.35503834479087
____
0.0
48.095677602178796
75.35503834479087
_____
*************end of training 
running canary eval
0.7437620334707771
threshold is:  3.594428539276123
correct cnt is:  0 all is:  1049 ratio is:  0.0
end of training perplexity: 48.095677602178796 perplexity_train: 75.35503834479087
____
0.0
48.095677602178796
75.35503834479087
_____
