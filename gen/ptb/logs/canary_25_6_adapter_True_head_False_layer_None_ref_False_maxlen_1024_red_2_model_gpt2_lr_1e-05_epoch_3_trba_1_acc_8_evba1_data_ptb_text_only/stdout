Namespace(adapter_reduction=2, add_adapter=True, add_canary=True, block_size=1024, canary_len=6, canary_rep=25, config_name=None, dataset_config_name=None, dataset_name='ptb_text_only', do_ref_model=False, eval_steps=100, gradient_accumulation_steps=8, hub_model_id=None, hub_token=None, learning_rate=1e-05, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, max_train_steps=None, model_name_or_path='gpt2', model_type=None, no_keep_linebreaks=False, num_train_epochs=3, num_warmup_steps=0, output_dir='./logs/', overwrite_cache=False, per_device_eval_batch_size=1, per_device_train_batch_size=1, preprocessing_num_workers=None, push_to_hub=False, seed=1234, tokenizer_name=None, train_file=None, train_head_only=False, train_layer_n_only=None, use_slow_tokenizer=False, validation_file=None, validation_split_percentage=5, weight_decay=0.0)
before canary len  42068
after canary len  42093
5000
model_params (million) 7.091712
model_params (million) 7.091712
training epoch 0
*************end of epoch 0 eval 
running canary eval
0.011067308256142524
threshold is:  3.785172939300537
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 0: perplexity: 58.749924693801944 perplexity_train: 87.81653136906236
____
0.0
58.749924693801944
87.81653136906236
_____
training epoch 1
*************end of epoch 1 eval 
running canary eval
0.014174941954451958
threshold is:  3.657775640487671
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 1: perplexity: 52.40842415202616 perplexity_train: 75.56286812458983
____
0.0
52.40842415202616
75.56286812458983
_____
training epoch 2
*************end of epoch 2 eval 
running canary eval
0.015285414629661018
threshold is:  3.626721143722534
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 2: perplexity: 50.9828341505622 perplexity_train: 72.83753207502424
____
0.0
50.9828341505622
72.83753207502424
_____
*************end of training 
running canary eval
0.015285414629661018
threshold is:  3.626721143722534
correct cnt is:  0 all is:  1049 ratio is:  0.0
end of training perplexity: 50.9828341505622 perplexity_train: 72.83749734339071
____
0.0
50.9828341505622
72.83749734339071
_____
