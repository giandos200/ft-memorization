Namespace(adapter_reduction=2, add_adapter=True, add_canary=True, block_size=1024, canary_len=6, canary_rep=25, config_name=None, dataset_config_name=None, dataset_name='ptb_text_only', do_ref_model=False, eval_steps=100, gradient_accumulation_steps=8, hub_model_id=None, hub_token=None, learning_rate=5e-06, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, max_train_steps=None, model_name_or_path='gpt2', model_type=None, no_keep_linebreaks=False, num_train_epochs=3, num_warmup_steps=0, output_dir='./logs/', overwrite_cache=False, per_device_eval_batch_size=1, per_device_train_batch_size=1, preprocessing_num_workers=None, push_to_hub=False, seed=1234, tokenizer_name=None, train_file=None, train_head_only=False, train_layer_n_only=None, use_slow_tokenizer=False, validation_file=None, validation_split_percentage=5, weight_decay=0.0)
before canary len  42068
after canary len  42093
5000
model_params (million) 7.091712
model_params (million) 7.091712
training epoch 0
*************end of epoch 0 eval 
running canary eval
0.005252076688814103
threshold is:  3.9575414657592773
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 0: perplexity: 71.22829359678646 perplexity_train: 111.22667797712406
____
0.0
71.22829359678646
111.22667797712406
_____
training epoch 1
*************end of epoch 1 eval 
running canary eval
0.007781670038593093
threshold is:  3.841144561767578
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 1: perplexity: 61.90567044724323 perplexity_train: 93.89563279597593
____
0.0
61.90567044724323
93.89563279597593
_____
training epoch 2
*************end of epoch 2 eval 
running canary eval
0.009153454764743496
threshold is:  3.8099441528320312
correct cnt is:  0 all is:  1049 ratio is:  0.0
epoch 2: perplexity: 59.91380535293379 perplexity_train: 90.09249359501564
____
0.0
59.91380535293379
90.09249359501564
_____
*************end of training 
running canary eval
0.009153454764743496
threshold is:  3.8099441528320312
correct cnt is:  0 all is:  1049 ratio is:  0.0
end of training perplexity: 59.91380535293379 perplexity_train: 90.09249359501564
____
0.0
59.91380535293379
90.09249359501564
_____
